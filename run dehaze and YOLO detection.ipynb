{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib.font_manager import fontManager\n",
    "#for i in sorted(fontManager.get_font_names()):\n",
    "#    print(i)\n",
    "matplotlib.rc('font', family='Microsoft JhengHei')\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_channel(image) : \n",
    "    H, W, _ = image.shape\n",
    "    patch_size = 15\n",
    "    pad_size = patch_size // 2\n",
    "    #創建 H*W 全零矩陣\n",
    "    dc = np.zeros((H, W), dtype=np.float32)\n",
    "    #用無限大的值填充的用意是取local min才不會影響到取值\n",
    "    imJ = np.pad(image ,((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant', constant_values=np.inf)   \n",
    "    #計算暗通道\n",
    "    for j in range(H):\n",
    "        for i in range(W):\n",
    "            #遍例3通道, 所有patch為15\n",
    "            patch = imJ[j:(j+patch_size), i:(i+patch_size),:]\n",
    "            #將patch中抓到的local min存到dc(j, i)裡\n",
    "            dc[j, i] = np.min(patch)\n",
    "            \n",
    "    return dc\n",
    "\n",
    "\n",
    "def atmospheric_light(image, dark_channel):\n",
    "\t#在暗通道中找最亮的像素，並在原彩圖中找到對應的位置，來計算大氣光的顏色\n",
    "\tH, W, _ = image.shape\n",
    "\timsize = H * W\t\t\t\t\t\t\t\t\t\t\t\t\t#計算圖像總像素數量\n",
    "\tnumpx = np.floor(imsize / 1000).astype(int)\t\t\t\t\t\t#計算要選擇的像素數量，選前0.1%，並向下取整\n",
    "\tdark_channel_Vec = dark_channel.ravel()\t\t\t\t\t\t\t#將dark_channel展平成 imsize *1 的列向量\n",
    "\tImVec = image.reshape(imsize, 3)\t\t\t\t\t\t\t\t#將原始影像image展平成 imsize * 3 的矩陣\n",
    "\tindices = np.argsort(dark_channel_Vec)\t\t\t\t\t\t\t#對暗通道進行升序排序，indices=索引值\n",
    "\tindices = indices[-numpx:]\t\t\t\t\t\t\t\t\t\t#選擇排序後最亮的0.1%，計算從哪裡開始提取索引的起點，並到end\n",
    "\tatmSum = np.zeros(3, dtype=np.float32)\t\t\t\t\t\t\t#計算大氣光的顏色，創建 1 * 3 全0矩陣，用來儲存最亮像素的顏色值累加和\n",
    "\n",
    "\t#遍例所有選中的像素\n",
    "\tfor ind in range(numpx):\n",
    "\t\tatmSum += ImVec[indices[ind]]\t\t\t\t\t\t\t\t#將每個選中像素的RGB顏色值累加到atmSum\n",
    "\n",
    "\tA = atmSum / numpx\t\t\t\t\t\t\t\t\t\t\t\t#將atmSum取平均，即為大氣光的顏色\n",
    "\n",
    "\treturn A\n",
    "\n",
    "\n",
    "def fusion(original, dehaze_06, dehaze_12, dehaze_15):\n",
    "    original = original\n",
    "    dehaze_06 = dehaze_06\n",
    "    dehaze_12 = dehaze_12\n",
    "    dehaze_15 = dehaze_15\n",
    "\n",
    "    height, width, channels = original.shape\n",
    "    I = np.zeros((height, width, channels, 4), dtype=np.float32)\n",
    "    I[:, :, :, 0] = original\n",
    "    I[:, :, :, 1] = dehaze_06\n",
    "    I[:, :, :, 2] = dehaze_12\n",
    "    I[:, :, :, 3] = dehaze_15\n",
    "\n",
    "    r, c, _, N = I.shape\n",
    "\n",
    "    # 將對比度和飽和度結合為權重圖\n",
    "    W = np.ones((r, c, 3, N), dtype=np.float32) * contrast(I) * saturation(I)\n",
    "\n",
    "    # 加個 eps 避免除0 & 歸一化 \n",
    "    W = W + 1e-12\n",
    "    W = W / np.tile(np.sum(W, axis=3)[:, :, :, np.newaxis], (1, 1, 1, N))   #或是這樣也可以 W = W / (np.sum(W, axis=2, keepdims=True))\n",
    "\n",
    "    # 創建一個空金字塔\n",
    "    pyr = gaussian_pyramid(np.zeros((r, c, 3), dtype=np.float32))\n",
    "    nlev = len(pyr)\n",
    "\n",
    "    # 多分辨率融合\n",
    "    for i in range(N):\n",
    "        # 從每個輸入圖像構建金字塔\n",
    "        pyrW = gaussian_pyramid(W[:, :, :, i])\n",
    "        pyrI = laplacian_pyramid(I[:, :, :, i])\n",
    "\n",
    "        # 融合\n",
    "        for l in range(nlev):\n",
    "            pyr[l] = pyr[l] + pyrW[l] * pyrI[l]\n",
    "\n",
    "    # 重建\n",
    "    R = reconstruct_laplacian_pyramid(pyr)\n",
    "    R_clip = np.clip(R, 0, 1)\n",
    "    \n",
    "    return R_clip\n",
    "\n",
    "\n",
    "def contrast(I):\n",
    "    h = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=np.float32)  # Laplacian filter\n",
    "    N = I.shape[3]\n",
    "    C = np.zeros((I.shape[0], I.shape[1], 3, N), dtype=np.float32)\n",
    "\n",
    "    for i in range(N):\n",
    "        mono = cv2.cvtColor(I[:, :, :, i], cv2.COLOR_BGR2GRAY)\n",
    "        mono = cv2.cvtColor(mono, cv2.COLOR_GRAY2BGR)\n",
    "        C[:, :, :, i] = np.abs(cv2.filter2D(mono, -1, h, borderType=cv2.BORDER_REPLICATE))\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def saturation(I):\n",
    "    N = I.shape[3]\n",
    "    C = np.zeros((I.shape[0], I.shape[1], 3, N), dtype=np.float32)\n",
    "\n",
    "    for i in range(N):\n",
    "        # 飽和度計算為顏色通道的標準差\n",
    "        R = I[:, :, 0, i]\n",
    "        G = I[:, :, 1, i]\n",
    "        B = I[:, :, 2, i]\n",
    "        mu = (R + G + B) / 3\n",
    "        sat = np.sqrt(((R - mu)**2 + (G - mu)**2 + (B - mu)**2) / 3)\n",
    "        sat = cv2.cvtColor(sat, cv2.COLOR_GRAY2BGR)\n",
    "        C[:, :, :, i] = sat\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def pyramid_filter():\n",
    "    return np.array([0.0625, 0.25, 0.375, 0.25, 0.0625])\n",
    "filter = pyramid_filter()\n",
    "\n",
    "\n",
    "def downsample(I, filter):\n",
    "    # 與自定義 filter 進行卷積\n",
    "    R = cv2.filter2D(I, -1, np.expand_dims(filter,axis=0), borderType=cv2.BORDER_REFLECT)     # 水平\n",
    "    R = cv2.filter2D(R, -1, np.expand_dims(filter,axis=1), borderType=cv2.BORDER_REFLECT)     # 垂直\n",
    "\n",
    "    # 下採樣\n",
    "    R = R[::2, ::2, :]\n",
    "    return R\n",
    "\n",
    "\n",
    "def upsample(I, odd, filter):\n",
    "    # 增加分辨率\n",
    "    I = np.pad(I, [(1, 1), (1, 1), (0, 0)], mode='edge')  # 用1像素邊界填充圖像\n",
    "    r, c, k = 2 * I.shape[0], 2 * I.shape[1], I.shape[2]\n",
    "    R = np.zeros((r, c, k))\n",
    "\n",
    "    R[0:r:2, 0:c:2, :] = 4 * I                          # R[0:r:2, 0:c:2, :] 和 R[::2, ::2, :] 是一樣意思的\n",
    "                                                        # 4 * I 可以看作是一種插值方式，將原始像素的值擴展到更大的區域，\n",
    "                                                        # 以維持亮度或顏色的一致性，這方法可以幫助在上採樣過程中減少亮度或顏色的損失。\n",
    "    # 插值，與可分離濾波器進行卷積\n",
    "    R = cv2.filter2D(R, -1, np.expand_dims(filter,axis=0), borderType=cv2.BORDER_REFLECT)   # 就算不指定填充邊界的方式，cv2.filter2D默認使用cv2.BORDER_CONSTANT\n",
    "    R = cv2.filter2D(R, -1, np.expand_dims(filter,axis=1), borderType=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # 刪除邊界\n",
    "    R = R[2:r-2-odd[0], 2:c-2-odd[1], :]\n",
    "    return R\n",
    "\n",
    "\n",
    "def gaussian_pyramid(I, nlev=None):\n",
    "    r = I.shape[0]\n",
    "    c = I.shape[1]\n",
    "\n",
    "    if nlev is None:\n",
    "        # 計算金字塔最高層數\n",
    "        nlev = int(np.floor(np.log2(min(r, c))))\n",
    "\n",
    "    # 創建包含 nlev 個元素的全None列表，第0層=原始影像\n",
    "    pyr = [None] * nlev\n",
    "    pyr[0] = I.copy()\n",
    "\n",
    "    # 遞迴式的下採樣\n",
    "    for l in range(1, nlev):\n",
    "        pyr[l] = downsample(pyr[l-1], filter)\n",
    "\n",
    "    return pyr\n",
    "\n",
    "\n",
    "def laplacian_pyramid(I, nlev=None):\n",
    "    r = I.shape[0]\n",
    "    c = I.shape[1]\n",
    "\n",
    "    if nlev is None:\n",
    "        # 計算金字塔最高層數\n",
    "        nlev = int(np.floor(np.log2(min(r, c))))\n",
    "\n",
    "    # 遞迴建立金字塔\n",
    "    pyr = [None] * nlev\n",
    "    filter = pyramid_filter()\n",
    "    J = I.copy()\n",
    "\n",
    "    for l in range(nlev - 1):\n",
    "        # 應用低通濾波器，然後下採樣\n",
    "        I = downsample(J, filter)\n",
    "        odd = (2 * I.shape[0] - J.shape[0], 2 * I.shape[1] - J.shape[1])  # 檢查上採樣版本是否需要奇數\n",
    "        # 在每一層中，存儲圖像和上採樣低通版本之間的差異\n",
    "        pyr[l] = J - upsample(I, odd, filter)\n",
    "\n",
    "        J = I  # 繼續使用低通圖像\n",
    "\n",
    "    pyr[nlev - 1] = J  # 最粗糙的層包含剩餘的低通圖像\n",
    "\n",
    "    return pyr\n",
    "\n",
    "\n",
    "def reconstruct_laplacian_pyramid(pyr):\n",
    "    nlev = len(pyr)\n",
    "    r, c, _ = pyr[0].shape\n",
    "\n",
    "    R = pyr[nlev - 1].copy()\n",
    "    filter = pyramid_filter()\n",
    "\n",
    "    for l in range(nlev - 2, -1, -1):\n",
    "        odd = (2 * R.shape[0] - pyr[l].shape[0], 2 * R.shape[1] - pyr[l].shape[1])\n",
    "        R = pyr[l] + upsample(R, odd, filter)\n",
    "    R = R.astype(np.float32)\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_transmission_dehaze(original_norm, d_GF, A, C, beta):\n",
    "\n",
    "    t = np.exp(-beta*d_GF)\n",
    "    selected_t = np.clip(t, 0.1, 1)\n",
    "\n",
    "    I_dehaze = np.zeros_like(original_norm)\n",
    "    for i in range(C):\n",
    "        I_dehaze[:, :, i] = (original_norm[:, :, i] - A[0, 0, i]) / (selected_t) + A[0, 0, i]\n",
    "    I_dehaze = np.clip(I_dehaze, 0, 1)\n",
    "\n",
    "    return original_norm, d_GF, selected_t, I_dehaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import random\n",
    "\n",
    "YOLO_model =  YOLO(\"yolo11x.pt\")\n",
    "\n",
    "def use_YOLO(image):\n",
    "    \n",
    "    target_classes = {\"car\", \"bus\", \"truck\", \"person\", \"motorcycle\", \"bicycle\", \"traffic light\", \"handbag\", \n",
    "                    \"orange\", \"cow\", \"skateboard\", \"dog\", \"bench\", \"umbrella\", \"surfboard\", \"frisbee\", \"banana\", \n",
    "                    \"backpack\", \"suitcase\", \"airplane\", \"train\",\"bear\", \"horse\", \"clock\", \"fire hydrant\", \"bird\"}\n",
    "    class_colors = {\n",
    "    'car': (0, 255, 0),             # 綠色\n",
    "    'bus': (255, 0, 0),             # 紅色\n",
    "    'truck': (0, 0, 255),           # 藍色\n",
    "    'person': (255, 255, 0),        # 黃色\n",
    "    'motorcycle': (255, 0, 255),    # 洋紅（紫紅）\n",
    "    'bicycle': (0, 255, 255),       # 青色（湖藍）\n",
    "    'traffic light': (255, 165, 0), # 橘色\n",
    "    'handbag': (128, 0, 128),       # 紫色\n",
    "    'orange': (255, 140, 0),        # 深橘（Dark Orange）\n",
    "    'cow': (139, 69, 19),           # 棕色（Saddle Brown）\n",
    "    'skateboard': (0, 128, 128),    # 藍綠色（Teal）\n",
    "    'dog': (160, 82, 45),           # 黃褐色（Sienna）\n",
    "    'bench': (105, 105, 105),       # 深灰色（Dim Gray）\n",
    "    'umbrella': (0, 100, 0),        # 深綠色（Dark Green）\n",
    "    'surfboard': (255, 105, 180),   # 粉紅色（Hot Pink）\n",
    "    'frisbee': (75, 0, 130),        # 靛藍（Indigo）\n",
    "    'banana': (255, 255, 102),      # 淺黃（Light Yellow）\n",
    "    'backpack': (70, 130, 180),     # 鋼藍色（Steel Blue）\n",
    "    'suitcase': (199, 21, 133),     # 中紫紅（Medium Violet Red）\n",
    "    'airplane': (0, 191, 255),      # 深天藍\n",
    "    'train': (255, 215, 0),         # 金黃色（Gold）\n",
    "    'bear': (128, 128, 0),          # 橄欖色（Olive）\n",
    "    'horse': (220, 20, 60),         # 猩紅色（Crimson）\n",
    "    'clock': (0, 0, 139),           # 深藍色（Dark Blue）\n",
    "    'fire hydrant': (255, 20, 147), # 深粉紅（Deep Pink）\n",
    "    'bird': (34, 139, 34)           # 森林綠（Forest Green）\n",
    "}\n",
    "\n",
    "    def get_color(label):\n",
    "        if label not in class_colors:\n",
    "            class_colors[label] = tuple(random.randint(0, 255) for _ in range(3))\n",
    "        return class_colors[label]\n",
    "    \n",
    "    results = YOLO_model(image)\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            label = YOLO_model.names[cls_id]\n",
    "            \n",
    "            if label.lower() in target_classes:\n",
    "                color = get_color(label)\n",
    "                print(f\"偵測到{label} (confidence: {conf:.2f})\")\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)#, (0, 255, 0), 2)\n",
    "                # cv2.putText(image, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
    "                cv2.putText(image, f\"{label}\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)#, (0, 255, 0), 2)\n",
    "            else:\n",
    "                print(f\"\\033[91m忽略類別: {label}\\033[0m\")\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCNN is predicting the depth of image : 03125946_64f412c2409657785......\u001b[0m\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 person, 554.8ms\n",
      "Speed: 1.7ms preprocess, 554.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.91)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 person, 490.5ms\n",
      "Speed: 1.9ms preprocess, 490.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.91)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : aerial......\u001b[0m\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 444.4ms\n",
      "Speed: 2.0ms preprocess, 444.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 464.8ms\n",
      "Speed: 1.5ms preprocess, 464.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : bear1......\u001b[0m\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 352x640 3 bears, 295.0ms\n",
      "Speed: 1.1ms preprocess, 295.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
      "偵測到bear (confidence: 0.94)\n",
      "偵測到bear (confidence: 0.83)\n",
      "偵測到bear (confidence: 0.32)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 352x640 3 bears, 305.2ms\n",
      "Speed: 1.4ms preprocess, 305.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "偵測到bear (confidence: 0.94)\n",
      "偵測到bear (confidence: 0.75)\n",
      "偵測到bear (confidence: 0.38)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : cones......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 horse, 376.1ms\n",
      "Speed: 1.2ms preprocess, 376.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到horse (confidence: 0.42)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 horse, 349.1ms\n",
      "Speed: 1.1ms preprocess, 349.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到horse (confidence: 0.45)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : DELHI_DUST_HAZE......\u001b[0m\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 motorcycle, 2 buss, 3 trucks, 305.1ms\n",
      "Speed: 1.0ms preprocess, 305.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到bus (confidence: 0.87)\n",
      "偵測到car (confidence: 0.85)\n",
      "偵測到car (confidence: 0.84)\n",
      "偵測到car (confidence: 0.83)\n",
      "偵測到car (confidence: 0.82)\n",
      "偵測到truck (confidence: 0.82)\n",
      "偵測到car (confidence: 0.80)\n",
      "偵測到bus (confidence: 0.76)\n",
      "偵測到car (confidence: 0.72)\n",
      "偵測到car (confidence: 0.71)\n",
      "偵測到truck (confidence: 0.66)\n",
      "偵測到motorcycle (confidence: 0.65)\n",
      "偵測到car (confidence: 0.64)\n",
      "偵測到car (confidence: 0.63)\n",
      "偵測到car (confidence: 0.54)\n",
      "偵測到person (confidence: 0.51)\n",
      "偵測到car (confidence: 0.46)\n",
      "偵測到car (confidence: 0.43)\n",
      "偵測到truck (confidence: 0.36)\n",
      "偵測到car (confidence: 0.26)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 1 person, 15 cars, 3 motorcycles, 2 buss, 3 trucks, 342.8ms\n",
      "Speed: 1.8ms preprocess, 342.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到bus (confidence: 0.88)\n",
      "偵測到car (confidence: 0.84)\n",
      "偵測到truck (confidence: 0.83)\n",
      "偵測到car (confidence: 0.83)\n",
      "偵測到truck (confidence: 0.83)\n",
      "偵測到car (confidence: 0.82)\n",
      "偵測到bus (confidence: 0.81)\n",
      "偵測到car (confidence: 0.79)\n",
      "偵測到car (confidence: 0.79)\n",
      "偵測到car (confidence: 0.72)\n",
      "偵測到motorcycle (confidence: 0.71)\n",
      "偵測到car (confidence: 0.70)\n",
      "偵測到person (confidence: 0.61)\n",
      "偵測到car (confidence: 0.57)\n",
      "偵測到car (confidence: 0.55)\n",
      "偵測到car (confidence: 0.53)\n",
      "偵測到motorcycle (confidence: 0.43)\n",
      "偵測到car (confidence: 0.42)\n",
      "偵測到truck (confidence: 0.37)\n",
      "偵測到car (confidence: 0.35)\n",
      "偵測到car (confidence: 0.31)\n",
      "偵測到motorcycle (confidence: 0.29)\n",
      "偵測到car (confidence: 0.26)\n",
      "偵測到car (confidence: 0.26)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : flickr16......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 2 persons, 1 train, 289.7ms\n",
      "Speed: 1.1ms preprocess, 289.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到train (confidence: 0.94)\n",
      "偵測到person (confidence: 0.65)\n",
      "偵測到person (confidence: 0.58)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 2 persons, 1 train, 321.3ms\n",
      "Speed: 1.2ms preprocess, 321.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到train (confidence: 0.94)\n",
      "偵測到person (confidence: 0.67)\n",
      "偵測到person (confidence: 0.59)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : foggy-037......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 4 cars, 2 buss, 3 trucks, 6 traffic lights, 283.6ms\n",
      "Speed: 0.9ms preprocess, 283.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到truck (confidence: 0.92)\n",
      "偵測到car (confidence: 0.92)\n",
      "偵測到car (confidence: 0.92)\n",
      "偵測到car (confidence: 0.88)\n",
      "偵測到car (confidence: 0.85)\n",
      "偵測到traffic light (confidence: 0.74)\n",
      "偵測到bus (confidence: 0.72)\n",
      "偵測到traffic light (confidence: 0.72)\n",
      "偵測到traffic light (confidence: 0.67)\n",
      "偵測到traffic light (confidence: 0.50)\n",
      "偵測到traffic light (confidence: 0.49)\n",
      "偵測到truck (confidence: 0.45)\n",
      "偵測到truck (confidence: 0.45)\n",
      "偵測到bus (confidence: 0.35)\n",
      "偵測到traffic light (confidence: 0.27)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 4 cars, 2 buss, 1 truck, 8 traffic lights, 354.2ms\n",
      "Speed: 0.9ms preprocess, 354.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到car (confidence: 0.92)\n",
      "偵測到car (confidence: 0.92)\n",
      "偵測到car (confidence: 0.86)\n",
      "偵測到truck (confidence: 0.85)\n",
      "偵測到car (confidence: 0.84)\n",
      "偵測到bus (confidence: 0.76)\n",
      "偵測到traffic light (confidence: 0.75)\n",
      "偵測到traffic light (confidence: 0.71)\n",
      "偵測到traffic light (confidence: 0.66)\n",
      "偵測到bus (confidence: 0.57)\n",
      "偵測到traffic light (confidence: 0.56)\n",
      "偵測到traffic light (confidence: 0.55)\n",
      "偵測到traffic light (confidence: 0.45)\n",
      "偵測到traffic light (confidence: 0.38)\n",
      "偵測到traffic light (confidence: 0.34)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : foggy-041......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 320x640 2 cars, 2 trucks, 334.7ms\n",
      "Speed: 1.6ms preprocess, 334.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "偵測到truck (confidence: 0.94)\n",
      "偵測到car (confidence: 0.90)\n",
      "偵測到car (confidence: 0.53)\n",
      "偵測到truck (confidence: 0.33)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 320x640 2 cars, 3 trucks, 264.7ms\n",
      "Speed: 1.6ms preprocess, 264.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "偵測到truck (confidence: 0.95)\n",
      "偵測到car (confidence: 0.89)\n",
      "偵測到car (confidence: 0.50)\n",
      "偵測到truck (confidence: 0.49)\n",
      "偵測到truck (confidence: 0.42)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : foggy-053......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 3 cars, 342.8ms\n",
      "Speed: 1.1ms preprocess, 342.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到car (confidence: 0.93)\n",
      "偵測到car (confidence: 0.87)\n",
      "偵測到car (confidence: 0.27)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 4 cars, 395.6ms\n",
      "Speed: 2.1ms preprocess, 395.6ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到car (confidence: 0.92)\n",
      "偵測到car (confidence: 0.86)\n",
      "偵測到car (confidence: 0.46)\n",
      "偵測到car (confidence: 0.42)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : forest......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 348.4ms\n",
      "Speed: 1.5ms preprocess, 348.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 393.6ms\n",
      "Speed: 1.5ms preprocess, 393.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : forest2......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 285.3ms\n",
      "Speed: 1.2ms preprocess, 285.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 356.7ms\n",
      "Speed: 1.3ms preprocess, 356.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : hazy mountain......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 person, 1 backpack, 337.3ms\n",
      "Speed: 1.2ms preprocess, 337.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.90)\n",
      "偵測到backpack (confidence: 0.80)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 person, 1 backpack, 356.2ms\n",
      "Speed: 1.2ms preprocess, 356.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.90)\n",
      "偵測到backpack (confidence: 0.80)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : horses......\u001b[0m\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 1 truck, 5 horses, 355.6ms\n",
      "Speed: 0.7ms preprocess, 355.6ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到horse (confidence: 0.94)\n",
      "偵測到horse (confidence: 0.92)\n",
      "偵測到horse (confidence: 0.92)\n",
      "偵測到horse (confidence: 0.90)\n",
      "偵測到horse (confidence: 0.88)\n",
      "偵測到truck (confidence: 0.41)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 5 horses, 352.3ms\n",
      "Speed: 0.8ms preprocess, 352.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到horse (confidence: 0.94)\n",
      "偵測到horse (confidence: 0.92)\n",
      "偵測到horse (confidence: 0.90)\n",
      "偵測到horse (confidence: 0.89)\n",
      "偵測到horse (confidence: 0.88)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : lviv......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 470.0ms\n",
      "Speed: 1.6ms preprocess, 470.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 (no detections), 410.5ms\n",
      "Speed: 1.8ms preprocess, 410.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : man......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 2 persons, 1 backpack, 470.3ms\n",
      "Speed: 1.2ms preprocess, 470.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.90)\n",
      "偵測到person (confidence: 0.87)\n",
      "偵測到backpack (confidence: 0.76)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 2 persons, 1 backpack, 496.8ms\n",
      "Speed: 1.2ms preprocess, 496.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.91)\n",
      "偵測到person (confidence: 0.88)\n",
      "偵測到backpack (confidence: 0.71)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : manor......\u001b[0m\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x512 1 clock, 498.3ms\n",
      "Speed: 1.4ms preprocess, 498.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "偵測到clock (confidence: 0.37)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x512 (no detections), 465.3ms\n",
      "Speed: 2.3ms preprocess, 465.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : ny12......\u001b[0m\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x480 (no detections), 452.6ms\n",
      "Speed: 1.2ms preprocess, 452.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x480 (no detections), 431.5ms\n",
      "Speed: 1.8ms preprocess, 431.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : plane......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 1 person, 1 airplane, 358.1ms\n",
      "Speed: 1.2ms preprocess, 358.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到airplane (confidence: 0.96)\n",
      "偵測到person (confidence: 0.28)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 3 persons, 1 airplane, 402.6ms\n",
      "Speed: 1.1ms preprocess, 402.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "偵測到airplane (confidence: 0.96)\n",
      "偵測到person (confidence: 0.55)\n",
      "偵測到person (confidence: 0.46)\n",
      "偵測到person (confidence: 0.41)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : pumpkins......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 (no detections), 394.6ms\n",
      "Speed: 1.2ms preprocess, 394.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 (no detections), 414.9ms\n",
      "Speed: 1.2ms preprocess, 414.9ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : road_input......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 1 car, 412.2ms\n",
      "Speed: 1.1ms preprocess, 412.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到car (confidence: 0.92)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 1 car, 486.7ms\n",
      "Speed: 1.2ms preprocess, 486.7ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到car (confidence: 0.92)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : sand_storm_g2-992......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 416x640 1 person, 4 cars, 2 trucks, 418.1ms\n",
      "Speed: 1.0ms preprocess, 418.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "偵測到person (confidence: 0.93)\n",
      "偵測到car (confidence: 0.88)\n",
      "偵測到car (confidence: 0.73)\n",
      "偵測到truck (confidence: 0.64)\n",
      "偵測到car (confidence: 0.61)\n",
      "偵測到car (confidence: 0.58)\n",
      "偵測到truck (confidence: 0.48)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 416x640 1 person, 4 cars, 1 truck, 386.5ms\n",
      "Speed: 1.2ms preprocess, 386.5ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "偵測到person (confidence: 0.93)\n",
      "偵測到car (confidence: 0.86)\n",
      "偵測到car (confidence: 0.84)\n",
      "偵測到car (confidence: 0.78)\n",
      "偵測到car (confidence: 0.66)\n",
      "偵測到truck (confidence: 0.51)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : S__141287475_0......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 417.5ms\n",
      "Speed: 1.8ms preprocess, 417.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 356.2ms\n",
      "Speed: 1.4ms preprocess, 356.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : S__145227800_0......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 483.9ms\n",
      "Speed: 1.4ms preprocess, 483.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 384x640 (no detections), 377.7ms\n",
      "Speed: 1.7ms preprocess, 377.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : S__145227821_0......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x384 (no detections), 376.8ms\n",
      "Speed: 1.5ms preprocess, 376.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x384 (no detections), 358.2ms\n",
      "Speed: 1.7ms preprocess, 358.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : S__145227826_0......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 fire hydrant, 343.6ms\n",
      "Speed: 1.7ms preprocess, 343.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到fire hydrant (confidence: 0.37)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 1 fire hydrant, 315.6ms\n",
      "Speed: 1.3ms preprocess, 315.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到fire hydrant (confidence: 0.44)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : tiananmen......\u001b[0m\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 6 birds, 338.6ms\n",
      "Speed: 1.3ms preprocess, 338.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到bird (confidence: 0.37)\n",
      "偵測到bird (confidence: 0.36)\n",
      "偵測到bird (confidence: 0.35)\n",
      "偵測到bird (confidence: 0.35)\n",
      "偵測到bird (confidence: 0.28)\n",
      "偵測到bird (confidence: 0.28)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 5 birds, 364.6ms\n",
      "Speed: 1.3ms preprocess, 364.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到bird (confidence: 0.36)\n",
      "偵測到bird (confidence: 0.29)\n",
      "偵測到bird (confidence: 0.28)\n",
      "偵測到bird (confidence: 0.26)\n",
      "偵測到bird (confidence: 0.26)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : train......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 1 train, 4 traffic lights, 321.7ms\n",
      "Speed: 1.1ms preprocess, 321.7ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到train (confidence: 0.68)\n",
      "偵測到traffic light (confidence: 0.66)\n",
      "偵測到traffic light (confidence: 0.66)\n",
      "偵測到traffic light (confidence: 0.34)\n",
      "偵測到traffic light (confidence: 0.33)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 448x640 1 train, 5 traffic lights, 341.5ms\n",
      "Speed: 1.2ms preprocess, 341.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "偵測到train (confidence: 0.81)\n",
      "偵測到traffic light (confidence: 0.61)\n",
      "偵測到traffic light (confidence: 0.58)\n",
      "偵測到traffic light (confidence: 0.35)\n",
      "偵測到traffic light (confidence: 0.28)\n",
      "偵測到traffic light (confidence: 0.26)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : tree2......\u001b[0m\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x640 (no detections), 455.4ms\n",
      "Speed: 2.2ms preprocess, 455.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 640x640 (no detections), 449.8ms\n",
      "Speed: 2.7ms preprocess, 449.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "\u001b[33mCNN is predicting the depth of image : ts13......\u001b[0m\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\u001b[33mPyramid fusion......\u001b[0m\n",
      "有霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 3 persons, 335.9ms\n",
      "Speed: 1.1ms preprocess, 335.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.78)\n",
      "偵測到person (confidence: 0.66)\n",
      "偵測到person (confidence: 0.51)\n",
      "去霧圖偵測到的物件 : \n",
      "\n",
      "0: 480x640 4 persons, 332.5ms\n",
      "Speed: 1.2ms preprocess, 332.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "偵測到person (confidence: 0.78)\n",
      "偵測到person (confidence: 0.65)\n",
      "偵測到person (confidence: 0.55)\n",
      "偵測到person (confidence: 0.32)\n",
      "\u001b[32mDone\u001b[0m \n",
      "\n",
      "總共處理了 29 張影像\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'data'\n",
    "output_folder = 'dehaze and YOLO result'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "CNN_model = load_model('model+weights.h5', compile=False)\n",
    "\n",
    "img_count = 0\n",
    "\n",
    "# 遍歷資料夾A中的所有 PNG 檔案\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        image_name = os.path.splitext(filename)[0]\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        # print(image_name, \"\\n\")\n",
    "        image_output_folder = os.path.join(output_folder, image_name)\n",
    "        \n",
    "        original = cv2.imread(f'{image_path}')\n",
    "        ori_resize = cv2.resize(original, (224, 224)) / 255.0\n",
    "        original_norm = original.astype(np.float32) / 255.0\n",
    "        gray_image = cv2.cvtColor(original_norm, cv2.COLOR_BGR2GRAY)\n",
    "        CNN_input = np.expand_dims(ori_resize, axis=0)\n",
    "        CNN_input = np.array(CNN_input)\n",
    "        print(f\"\\033[33mCNN is predicting the depth of image : {image_name}......\\033[0m\")\n",
    "        predictions = CNN_model.predict(CNN_input)\n",
    "        d = predictions[0]\n",
    "        H, W, C = original.shape\n",
    "        d = cv2.resize(d, (W, H))\n",
    "        radius = round(np.minimum(H, W) / 50)\n",
    "        d_GF = cv2.ximgproc.guidedFilter(guide=gray_image, src=d, radius=radius, eps=1e-5)\n",
    "\n",
    "        dc = dark_channel(original_norm)\n",
    "        A = atmospheric_light(original_norm, dc)\n",
    "        if A.shape == (3,):\n",
    "            A = A.reshape(1, 1, 3)\n",
    "\n",
    "        original_norm, d_GF, selected_t_06, I_dehaze_06 = restore_transmission_dehaze(original_norm, d_GF, A, C, beta=0.6)\n",
    "        _            , _   , selected_t_12, I_dehaze_12 = restore_transmission_dehaze(original_norm, d_GF, A, C, beta=1.2)\n",
    "        _            , _   , selected_t_18, I_dehaze_15 = restore_transmission_dehaze(original_norm, d_GF, A, C, beta=1.5)\n",
    "\n",
    "        print(\"\\033[33mPyramid fusion......\\033[0m\")\n",
    "        fusion_result = fusion(original_norm, I_dehaze_06, I_dehaze_12, I_dehaze_15)\n",
    "        fusion_result_8bit_255 = ((np.clip(fusion_result, 0, 1))*255).astype(np.uint8)\n",
    "\n",
    "        color_d_GF_INFERNO = cv2.applyColorMap((255 - (np.clip(d_GF, 0, 1)*255)).astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
    "        ori_to_save = (np.clip(original_norm, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "        print(\"有霧圖偵測到的物件 : \")\n",
    "        ori_use_yolo = use_YOLO(ori_to_save)\n",
    "        print(\"去霧圖偵測到的物件 : \")\n",
    "        dehaze_use_yolo = use_YOLO(fusion_result_8bit_255)\n",
    "\n",
    "        concat_image = cv2.hconcat([ori_use_yolo, dehaze_use_yolo])\n",
    "        concat_path = os.path.join(output_folder, f'{image_name}_concat (dehaze and YOLO).png')\n",
    "        cv2.imwrite(concat_path, concat_image)\n",
    "        print(\"\\033[32mDone\\033[0m\", \"\\n\")\n",
    "\n",
    "        img_count += 1\n",
    "\n",
    "print(f\"總共處理了 {img_count} 張影像\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 1.0)\n",
    "engine.say(\"程式碼已執行完畢，快點來啦\")\n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_111_forYOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
